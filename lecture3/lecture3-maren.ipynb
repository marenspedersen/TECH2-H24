{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Grouping and aggregation with pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aggregation and reduction\n",
    "\n",
    "Similar to NumPy, pandas supports data aggregation and reduction functions \n",
    "such as computing sums or averages. By _\"aggregation\"_ or _\"reduction\"_ \n",
    "we mean that the result of a computation has a lower dimension than the original data: for example, the mean reduces a series of observations (1 dimension) into a scalar value (0 dimensions).\n",
    "\n",
    "Unlike NumPy, these operations\n",
    "can be applied to subsets of the data which have been\n",
    "grouped according to some criterion. \n",
    "\n",
    "Such operations are often referred to as *split-apply-combine* (see the official [user guide](https://pandas.pydata.org/docs/user_guide/groupby.html)) as they involve these three steps:\n",
    "\n",
    "1. *Split* data into groups based on some criteria;\n",
    "2. *Apply* some function to each group separately; and\n",
    "3. *Combine* the results into a single `DataFrame` or `Series`.\n",
    "\n",
    "See also the pandas [cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for an illustration of such operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set the path pointing to the folder which contains the data files used in this lecture. You may need to adapt it to your own environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to use files in the local data/ directory\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "# Uncomment this to load data directly from GitHub\n",
    "# DATA_PATH = 'https://raw.githubusercontent.com/richardfoltyn/TECH2-H24/main/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with entire DataFrames\n",
    "\n",
    "The simplest way to perform data reduction is to invoke the desired\n",
    "function on the entire `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived     0.383838\n",
       "Pclass       2.308642\n",
       "Age         29.699118\n",
       "Fare        32.204208\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in Titanic passenger data, set PassenderId column as index\n",
    "df = pd.read_csv(f'{DATA_PATH}/titanic.csv', index_col='PassengerId')\n",
    "\n",
    "# Compute mean of all numerical columns\n",
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Methods such as [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html) \n",
    "are by default applied column-wise to each\n",
    "column. The `numeric_only=True` argument is used to discard\n",
    "all non-numeric columns (depending on the version of pandas, `mean()` will\n",
    "issue a warning if there are non-numerical columns in the `DataFrame`).\n",
    "\n",
    "One big advantage over NumPy is that missing values (represented\n",
    "by `np.nan`) are automatically ignored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean using Pandas: 29.69911764705882\n",
      "Mean using NumPy:  nan\n"
     ]
    }
   ],
   "source": [
    "# mean() automatically drops missing observations\n",
    "mean_pandas = df['Age'].mean()\n",
    "\n",
    "# Compare this to the NumPy variant:\n",
    "import numpy as np\n",
    "\n",
    "# Returns NaN since some ages are missing (coded as NaN)\n",
    "mean_numpy = np.mean(df['Age'].to_numpy())\n",
    "\n",
    "print(f'Mean using Pandas: {mean_pandas}')\n",
    "print(f'Mean using NumPy:  {mean_numpy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen previously, NumPy implements an additional set of aggregation functions which drop NaNs, for example [`np.nanmean()`](https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Working on subsets of data (grouping)\n",
    "\n",
    "Applying aggregation functions to the entire `DataFrame` is similar\n",
    "to what we can do with NumPy. The added flexibility of pandas\n",
    "becomes obvious once we want to apply these functions to subsets of\n",
    "data, i.e., groups which we can define based on values or index labels.\n",
    "\n",
    "For example, we can easily group passengers by class using\n",
    "[`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import Titanic data set, set PassenderId column as index\n",
    "df = pd.read_csv(f'{DATA_PATH}/titanic.csv', index_col='PassengerId')\n",
    "\n",
    "# Group observations by accommodation class (first, second, third)\n",
    "groups = df.groupby(['Pclass'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here `groups` is a special pandas objects which can subsequently be\n",
    "used to process group-specific data. To compute the group-wise\n",
    "averages, we can simply run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472826</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>20.662183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242363</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived        Age       Fare\n",
       "Pclass                                \n",
       "1       0.629630  38.233441  84.154687\n",
       "2       0.472826  29.877630  20.662183\n",
       "3       0.242363  25.140620  13.675550"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.mean(numeric_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Groups support column indexing: if we want to only compute the\n",
    "total fare paid by passengers in each class, we can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    18177.4125\n",
       "2     3801.8417\n",
       "3     6714.6951\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups['Fare'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Built-in aggregations\n",
    "\n",
    "There are numerous routines to aggregate grouped data, for example:\n",
    "\n",
    "- [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html):\n",
    "    averages within each group\n",
    "- [`sum()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html):\n",
    "    sum values within each group\n",
    "- [`std()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html), \n",
    "    [`var()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html): \n",
    "    within-group standard deviation and variance\n",
    "- [`quantile()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html):\n",
    "    compute quantiles within each group\n",
    "- [`size()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html): \n",
    "    number of observations in each group\n",
    "- [`count()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html):\n",
    "    number of non-missing observations in each group\n",
    "- [`first()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html), \n",
    "    [`last()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html): \n",
    "    first and last elements in each group\n",
    "-   [`min()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html), \n",
    "    [`max()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html): \n",
    "    minimum and maximum elements within a group\n",
    "\n",
    "See the [official documentation](https://pandas.pydata.org/docs/user_guide/groupby.html#built-in-aggregation-methods) for a complete list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Example: Number of elements within each group*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    216\n",
       "2    184\n",
       "3    491\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.size()       # return number of elements in each group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Return first observation of each group*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived   Age     Sex     Fare\n",
       "Pclass                                 \n",
       "1              1  38.0  female  71.2833\n",
       "2              1  14.0  female  30.0708\n",
       "3              0  22.0    male   7.2500"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[['Survived', 'Age', 'Sex', 'Fare']].first()      # return first observation in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the Titanic data set to perform the following aggregations:\n",
    "<ol>\n",
    "    <li>Compute the average survival rate by sex (stored in the <TT>Sex</TT> column).</li>\n",
    "    <li>Count the number of passengers aged 50+. Compute the average survival rate by sex for this group.</li>\n",
    "    <li>Count the number of passengers below the age of 20 by class and sex. Compute the average survival rate for this group (by class and sex).</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2481726645.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[130], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    df2 = df.loc[df['Sex']\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "df2 = df.loc[df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    0.909091\n",
       "male      0.134615\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('Age >= 50').groupby('Sex')['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Sex   \n",
       "1       female    0.928571\n",
       "        male      0.571429\n",
       "2       female    1.000000\n",
       "        male      0.526316\n",
       "3       female    0.533333\n",
       "        male      0.190476\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('Age < 20').groupby(['Pclass', 'Sex'])['Survived'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Writing custom aggregations\n",
    "\n",
    "We can create custom aggregation routines by calling \n",
    "[`agg()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html)\n",
    "(short-hand for [`aggregate()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html))\n",
    "on the grouped object. These functions operate on one column at a time, so it is only possible to use observations from that column for computations. \n",
    "\n",
    "For example, we can alternatively call the built-in aggregation functions we just covered via `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    38.233441\n",
       "2    29.877630\n",
       "3    25.140620\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate group means in needlessly complicated way\n",
    "groups[\"Age\"].agg(\"mean\")\n",
    "\n",
    "# More direct approach:\n",
    "# groups[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, we _have to_ use `agg()` if there is no built-in function to perform the desired aggregation.\n",
    "To illustrate, imagine that we want to count the number of passengers aged 40+ in each class. There is no built-in function to achieve this, so we need to use `agg()` combined with a custom function to perform the desired aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    81\n",
       "2    37\n",
       "3    45\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "groups['Age'].agg(lambda x: np.sum(x >= 40))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that we called `agg()` only on the column `Age`, otherwise\n",
    "the function would be applied to every column separately, which is not\n",
    "what we want."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying multiple functions at once\n",
    "\n",
    "It is possible to apply multiple functions in a single call by passing a list of functions. These can be passed as strings or as callables (functions).\n",
    "\n",
    "*Example: Applying multiple functions to a **single** column*\n",
    "\n",
    " To compute the mean and median passenger age by class, we proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.233441</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.877630</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.140620</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean  median\n",
       "Pclass                   \n",
       "1       38.233441    37.0\n",
       "2       29.877630    29.0\n",
       "3       25.140620    24.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups['Age'].agg(['mean', 'median'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that we could have also specified these function by passing references to the corresponding NumPy functions instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/2zpy7syn66z_7t5th2_z4bc40000gn/T/ipykernel_23011/3990418967.py:1: FutureWarning: The provided callable <function mean at 0x10d762660> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  groups['Age'].agg([np.mean, np.median])\n",
      "/var/folders/t4/2zpy7syn66z_7t5th2_z4bc40000gn/T/ipykernel_23011/3990418967.py:1: FutureWarning: The provided callable <function median at 0x10d891da0> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  groups['Age'].agg([np.mean, np.median])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.233441</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.877630</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.140620</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean  median\n",
       "Pclass                   \n",
       "1       38.233441    37.0\n",
       "2       29.877630    29.0\n",
       "3       25.140620    24.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups['Age'].agg([np.mean, np.median])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following more advanced syntax allows us to create new column names using existing columns and some operation:\n",
    "\n",
    "```python\n",
    "    groups.agg(\n",
    "        new_column_name1=('column_name1', 'operation1'),\n",
    "        new_column_name2=('column_name2', 'operation2'),\n",
    "        ...\n",
    "    )\n",
    "```\n",
    "This is called [\"named aggregation\"](https://pandas.pydata.org/docs/user_guide/groupby.html#named-aggregation)\n",
    "as the keywords determine the output column _names_.\n",
    "\n",
    "*Example: Applying multiple functions to **multiple** columns*\n",
    "\n",
    "The following code computes the average age and the highest fare in a single aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_age</th>\n",
       "      <th>max_fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.233441</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.877630</td>\n",
       "      <td>73.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.140620</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        average_age  max_fare\n",
       "Pclass                       \n",
       "1         38.233441  512.3292\n",
       "2         29.877630   73.5000\n",
       "3         25.140620   69.5500"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.agg(\n",
    "    average_age=('Age', 'mean'), \n",
    "    max_fare=('Fare', 'max')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the most flexible aggregation method is `apply()` which calls a\n",
    "given function, passing the _entire_ group-specific subset of data (including\n",
    "all columns) as an argument. You need to use apply if data from more than one column is required to compute a statistic of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the Titanic data set to perform the following aggregations:\n",
    "<ol>\n",
    "    <li>Compute the minimum, maximum and average age by embarkation port (stored in the column <TT>Embarked</TT>) in a single <TT>agg()</TT> operation.\n",
    "    Note that there are several ways to solve this problem.</li>\n",
    "    <li>Compute the number of passengers, the average age and the fraction of women by embarkation port in a single <TT>agg()</TT> operation. This one is more challenging and probably requires use of <TT>lambda</TT> expressions.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['Female'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(number_passenger \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m), avg_age \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m      2\u001b[0m                            frac_women \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:190\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:423\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_dict_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1608\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1603\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[1;32m   1606\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1607\u001b[0m ):\n\u001b[0;32m-> 1608\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dict_like(\n\u001b[1;32m   1609\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[1;32m   1610\u001b[0m     )\n\u001b[1;32m   1611\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:462\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m is_groupby \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[1;32m    461\u001b[0m func \u001b[38;5;241m=\u001b[39m cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[0;32m--> 462\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_dictlike_arg(op_name, selected_obj, func)\n\u001b[1;32m    464\u001b[0m is_non_unique_col \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    465\u001b[0m     selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_obj\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    467\u001b[0m )\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:663\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    661\u001b[0m     cols \u001b[38;5;241m=\u001b[39m Index(\u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;241m.\u001b[39mdifference(obj\u001b[38;5;241m.\u001b[39mcolumns, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    665\u001b[0m aggregator_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['Female'] do not exist\""
     ]
    }
   ],
   "source": [
    "df.groupby('Embarked').agg(number_passenger = ('Age','size'), avg_age = ('Age','mean'), \n",
    "                           frac_women = ('Female', 'mean'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "In the previous section, we combined grouping and reduction, i.e., data at the group level was reduced to a single statistic such as the mean. Alternatively, we can combine grouping with the\n",
    "[`transform()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html) function which assigns the result of a computation to each observation within a group and consequently leaves the number of observations unchanged.\n",
    "\n",
    "For example, for _each_ observation we could compute the average fare by class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      25.140620\n",
       "2      38.233441\n",
       "3      25.140620\n",
       "4      38.233441\n",
       "5      25.140620\n",
       "         ...    \n",
       "887    29.877630\n",
       "888    38.233441\n",
       "889    25.140620\n",
       "890    38.233441\n",
       "891    25.140620\n",
       "Name: Age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Pclass')['Age'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Avg_Age'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_Age\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Avg_Age'] not in index\""
     ]
    }
   ],
   "source": [
    "df[['Pclass','Age', 'Avg_Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Avg_Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>20.662183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Fare   Avg_Fare\n",
       "PassengerId                            \n",
       "1                 3   7.2500  13.675550\n",
       "2                 1  71.2833  84.154687\n",
       "3                 3   7.9250  13.675550\n",
       "4                 1  53.1000  84.154687\n",
       "5                 3   8.0500  13.675550\n",
       "6                 3   8.4583  13.675550\n",
       "7                 1  51.8625  84.154687\n",
       "8                 3  21.0750  13.675550\n",
       "9                 3  11.1333  13.675550\n",
       "10                2  30.0708  20.662183"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Avg_Fare'] = df.groupby('Pclass')[['Fare']].transform('mean')\n",
    "\n",
    "# Print results for each institution\n",
    "df[['Pclass', 'Fare', 'Avg_Fare']].head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, instead of collapsing the `DataFrame` to only 3 observations (one for each class), the number of observations remains the same, and the average fare is constant within each class. \n",
    "\n",
    "When would we want to use `transform()` instead of aggregation? Such use cases arise whenever we want to perform computations that include the individual value as well as an aggregate statistic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Deviation from average fare*\n",
    "\n",
    "Assume that we want to compute how much each passenger's fare differed from the average fare in their respective class. We could compute this using `transform()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_diff(x):\n",
    "    return x - np.min(x)\n",
    "\n",
    "df['Diff_Fare'] = df.groupby(['Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fare_Diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>-6.425550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>-12.871387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>-5.750550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>-31.054687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>-5.625550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>-5.217250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>-32.292187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>7.399450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>-2.542250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>9.408617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Fare  Fare_Diff\n",
       "PassengerId                            \n",
       "1                 3   7.2500  -6.425550\n",
       "2                 1  71.2833 -12.871387\n",
       "3                 3   7.9250  -5.750550\n",
       "4                 1  53.1000 -31.054687\n",
       "5                 3   8.0500  -5.625550\n",
       "6                 3   8.4583  -5.217250\n",
       "7                 1  51.8625 -32.292187\n",
       "8                 3  21.0750   7.399450\n",
       "9                 3  11.1333  -2.542250\n",
       "10                2  30.0708   9.408617"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute difference of passenger's fare and avg. fare paid within class\n",
    "df['Fare_Diff'] = df.groupby('Pclass')['Fare'].transform(lambda x: x - np.mean(x))\n",
    "\n",
    "# Print relevant columns\n",
    "df[['Pclass', 'Fare', 'Fare_Diff']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the Titanic data set to perform the following aggregations:\n",
    "<ol>\n",
    "    <li>Compute the <i>excess</i> fare paid by each passenger relative to the minimum fare by embarkation port and class, i.e., compute <i>Fare - min(Fare)</i>\n",
    "        by port and class.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Working with time series data\n",
    "\n",
    "In economics and finance, we frequently work with time series data, i.e., observations that are associated with a particular point in time (time stamp) or a time period. pandas offers comprehensive support for such data, in particular if the time stamp or time period is used as the index of a `Series` or `DataFrame`.\n",
    "This section presents a few of the most important concepts, see the official [documentation](https://pandas.pydata.org/docs/user_guide/timeseries.html) for a comprehensive guide.\n",
    "\n",
    "To illustrate, let's construct a set of daily data for the first three months of 2024, i.e., the period 2024-01-01 to 2024-03-31 using the \n",
    "[`date_range()`](https://pandas.pydata.org/docs/reference/api/pandas.date_range.html) function\n",
    "(we use the data format `YYYY-MM-DD` in this section, but pandas also supports other date formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-01    0\n",
       "2024-01-02    1\n",
       "2024-01-03    2\n",
       "2024-01-04    3\n",
       "2024-01-05    4\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "\n",
    "# Create sequence of dates from 2024-01-01 to 2024-03-31 \n",
    "# at daily frequency\n",
    "index = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "\n",
    "# Use date range as index for Series with some artificial data\n",
    "data = pd.Series(np.arange(len(index)), index=index)\n",
    "\n",
    "# Print first 5 observations\n",
    "data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with date/time indices\n",
    "\n",
    "pandas implements several convenient ways to select observations associated with a particular date or a set of dates. For example, if we want to select one specific date, we can pass it as a string to `.loc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select single observation by date\n",
    "data.loc['2024-01-01']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to select a time period by passing a start and end point (where the end point is included, as usual with label-based indexing in pandas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-01    0\n",
       "2024-01-02    1\n",
       "2024-01-03    2\n",
       "2024-01-04    3\n",
       "2024-01-05    4\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select first 5 days\n",
    "data.loc['2024-01-01':'2024-01-05']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A particularly useful way to index time periods is a to pass a partial index. For example, if we want to select all observations from January 2024, we could use the range `'2024-01-01':'2024-01-31'`, but it is much easier to specify the partial index `'2024-01'` instead which includes all observations from January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-01     0\n",
       "2024-01-02     1\n",
       "2024-01-03     2\n",
       "2024-01-04     3\n",
       "2024-01-05     4\n",
       "2024-01-06     5\n",
       "2024-01-07     6\n",
       "2024-01-08     7\n",
       "2024-01-09     8\n",
       "2024-01-10     9\n",
       "2024-01-11    10\n",
       "2024-01-12    11\n",
       "2024-01-13    12\n",
       "2024-01-14    13\n",
       "2024-01-15    14\n",
       "2024-01-16    15\n",
       "2024-01-17    16\n",
       "2024-01-18    17\n",
       "2024-01-19    18\n",
       "2024-01-20    19\n",
       "2024-01-21    20\n",
       "2024-01-22    21\n",
       "2024-01-23    22\n",
       "2024-01-24    23\n",
       "2024-01-25    24\n",
       "2024-01-26    25\n",
       "2024-01-27    26\n",
       "2024-01-28    27\n",
       "2024-01-29    28\n",
       "2024-01-30    29\n",
       "2024-01-31    30\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all observations from January 2024\n",
    "data.loc['2024-01']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lags, differences, and other useful transformations\n",
    "\n",
    "When working with time series data, we often need to create lags or leads of a variable (e.g., if we want to include lagged values in a regression model). In pandas, this is done using \n",
    "[`shift()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html)\n",
    "which shifts the index by the desired number of periods (default: 1). For example, invoking\n",
    "`shift(1)` creates lagged observations of each column in the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-01    NaN\n",
       "2024-01-02    0.0\n",
       "2024-01-03    1.0\n",
       "2024-01-04    2.0\n",
       "2024-01-05    3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lag observations by 1 period\n",
    "data.shift(1).head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first observation is now missing since there is no preceding observation which could have provided the lagged value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is \n",
    "[`diff()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html)\n",
    "which computes the difference between adjacent observations (the period over which the difference\n",
    "is taken can be passed as a parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-01    NaN\n",
       "2024-01-02    1.0\n",
       "2024-01-03    1.0\n",
       "2024-01-04    1.0\n",
       "2024-01-05    1.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute 1-period difference\n",
    "data.diff().head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `diff()` is identical to manually computing the difference with the lagged value like this:\n",
    "```python\n",
    "data - data.shift()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can use \n",
    "[`pct_change()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html)\n",
    "which computes the percentage change (the relative difference) over a given number of periods (default: 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-01         NaN\n",
       "2024-01-02         inf\n",
       "2024-01-03    1.000000\n",
       "2024-01-04    0.500000\n",
       "2024-01-05    0.333333\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute percentage change vs. previous period\n",
    "data.pct_change().head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is just a convenience method that is a short-cut for manually computing the percentage change:\n",
    "```python\n",
    "(data - data.shift()) / data.shift()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and aggregation\n",
    "\n",
    "Another useful feature of the time series support in pandas is *resampling* which is used to group observations by time period and apply some aggregation function.\n",
    "This can be accomplished using the \n",
    "[`resample()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html)\n",
    "method which in its simplest form takes a string argument that describes how observations should be grouped\n",
    "(`'YE'` for aggregation to years, `'QE'` for quarters, `'ME'` for months, `'W'` for weeks, etc.).\n",
    "\n",
    "For example, if we want to aggregate our 3 months of artificial daily data to monthly frequency, we would use `resample('ME')`. This returns an object which is very similar to the one returned by `groupby()` we studied previously, and we can call various aggregation methods such as `mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-31    15.0\n",
       "2024-02-29    45.0\n",
       "2024-03-31    75.0\n",
       "Freq: ME, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample to monthly frequency, aggregate to mean of daily observations \n",
    "# within each month\n",
    "data.resample('ME').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use `resample('W')` to resample to weekly frequency. Below,\n",
    "we combine this with the aggregator \n",
    "[`last()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.last.html) \n",
    "to return the last observation of each week (weeks by default start on Sundays):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-01-07     6\n",
       "2024-01-14    13\n",
       "2024-01-21    20\n",
       "2024-01-28    27\n",
       "2024-02-04    34\n",
       "2024-02-11    41\n",
       "2024-02-18    48\n",
       "2024-02-25    55\n",
       "2024-03-03    62\n",
       "2024-03-10    69\n",
       "2024-03-17    76\n",
       "2024-03-24    83\n",
       "2024-03-31    90\n",
       "Freq: W-SUN, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return last observation of each week\n",
    "data.resample('W').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
